{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5bALUwjAa9uH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bALUwjAa9uH",
        "outputId": "8a605b2a-2c8a-4e09-afb0-55e8b1032ce7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dipy\n",
            "  Downloading dipy-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from dipy) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.10/dist-packages (from dipy) (1.11.4)\n",
            "Requirement already satisfied: nibabel>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from dipy) (4.0.2)\n",
            "Requirement already satisfied: h5py>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from dipy) (3.9.0)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from dipy) (24.1)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from dipy) (4.66.4)\n",
            "Collecting trx-python>=0.2.9 (from dipy)\n",
            "  Downloading trx_python-0.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel>=3.0.0->dipy) (67.7.2)\n",
            "Collecting setuptools-scm (from trx-python>=0.2.9->dipy)\n",
            "  Downloading setuptools_scm-8.1.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deepdiff (from trx-python>=0.2.9->dipy)\n",
            "  Downloading deepdiff-7.0.1-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.8/80.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nibabel>=3.0.0 (from dipy)\n",
            "  Downloading nibabel-5.2.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ordered-set<4.2.0,>=4.1.0 (from deepdiff->trx-python>=0.2.9->dipy)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from setuptools-scm->trx-python>=0.2.9->dipy) (2.0.1)\n",
            "Installing collected packages: setuptools-scm, ordered-set, nibabel, deepdiff, trx-python, dipy\n",
            "  Attempting uninstall: nibabel\n",
            "    Found existing installation: nibabel 4.0.2\n",
            "    Uninstalling nibabel-4.0.2:\n",
            "      Successfully uninstalled nibabel-4.0.2\n",
            "Successfully installed deepdiff-7.0.1 dipy-1.9.0 nibabel-5.2.1 ordered-set-4.1.0 setuptools-scm-8.1.0 trx-python-0.3\n",
            "Collecting einops\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m776.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install dipy\n",
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "S4ilmcaWa0mN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4ilmcaWa0mN",
        "outputId": "87b3df7b-6f1d-4bf5-e24e-557449291519"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "mount_path = '/content/drive'\n",
        "drive_path = mount_path+\"/MyDrive/dti-transformer/code/cl-training\"\n",
        "test_data = mount_path+'/MyDrive/dti-transformer/dti_data'\n",
        "drive.mount(mount_path)\n",
        "os.chdir(drive_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cc75b2b9-310c-49f2-8c68-c9120d9bb97a",
      "metadata": {
        "id": "cc75b2b9-310c-49f2-8c68-c9120d9bb97a"
      },
      "outputs": [],
      "source": [
        "# Daniel Bandala @ nov-2022\n",
        "# dti-model validation script\n",
        "# general libraries\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from math import log10, sqrt\n",
        "# diffussion image processing\n",
        "from dipy.io.image import load_nifti\n",
        "# import torch libraries\n",
        "import torch\n",
        "from torch import nn\n",
        "# import dataset auxiliar libraries\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import mean_squared_error\n",
        "#from unet_model import DiffusionTensorModelUNet\n",
        "from data_loader_cl import data_preprocessing, normalize_data\n",
        "#from other.unet import UNet\n",
        "from torchvision.transforms import functional as TF\n",
        "from timeit import default_timer as timer\n",
        "import time\n",
        "# import model\n",
        "import sys, glob\n",
        "sys.path.insert(1, '../model')\n",
        "from dti_model import DiffusionTensorModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1iEWHWlTnwcB",
      "metadata": {
        "id": "1iEWHWlTnwcB"
      },
      "outputs": [],
      "source": [
        "results_path = drive_path+\"/results/FA\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6d1292e1-a110-4048-abc9-4ff818833c7f",
      "metadata": {
        "id": "6d1292e1-a110-4048-abc9-4ff818833c7f"
      },
      "outputs": [],
      "source": [
        "signals = 7\n",
        "maps = [\"FA\"] #\"MD\",\"MO\",\"L1\",\"L2\",\"L3\",FA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "FINCuRPbuGs7",
      "metadata": {
        "id": "FINCuRPbuGs7"
      },
      "outputs": [],
      "source": [
        "# load model\n",
        "checkpoint = torch.load(results_path+'/../dti_fa.weights') #dti_fa.weights FA_2023-03-30\n",
        "model = DiffusionTensorModel(\n",
        "    in_chans=signals,\n",
        "    out_chans=1,\n",
        "    img_size=140,\n",
        "    embed_dim=64,\n",
        "    n_heads=[1,2,4,8],\n",
        "    mlp_ratio=[2,2,4,4],\n",
        "    reduction_ratio=1,\n",
        "    depth_prob=0.2,\n",
        "    tanh_output=False\n",
        ")\n",
        "# use model in cpu for validation (gpu for training)\n",
        "_ = model.to('cpu')\n",
        "_ = model.load_state_dict(checkpoint) #torch.load(, map_location=torch.device('cpu'))\n",
        "_ = model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FNFfWrU7-oO9",
      "metadata": {
        "id": "FNFfWrU7-oO9"
      },
      "outputs": [],
      "source": [
        "# load model\n",
        "checkpoint = torch.load(results_path+'/unet/dti_rgb.weights') #dti_fa.weights FA_2023-03-30\n",
        "model = DiffusionTensorModelUNet(\n",
        "    in_chans=signals,\n",
        "    out_chans=3,\n",
        "    img_size=140,\n",
        "    embed_dim=64,\n",
        "    n_heads=[1,2,4,8],\n",
        "    mlp_ratio=[2,2,4,4],\n",
        "    reduction_ratio=1,\n",
        "    depth_prob=0.2,\n",
        "    tanh_output=False\n",
        ")\n",
        "# use model in cpu for validation (gpu for training)\n",
        "_ = model.to('cpu')\n",
        "_ = model.load_state_dict(checkpoint) #torch.load(, map_location=torch.device('cpu'))\n",
        "_ = model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "l4PsoaKaSujR",
      "metadata": {
        "id": "l4PsoaKaSujR"
      },
      "outputs": [],
      "source": [
        "# load unet model\n",
        "weights = torch.load(results_path+'/unet/dti_rgb.weights')\n",
        "model = UNet(\n",
        "    enc_channels=(signals,64,128,256,512,1024),\n",
        "    dec_channels=(1024,512,256,128,64),\n",
        "    out_chans=3,\n",
        "    img_size=140\n",
        ")\n",
        "# use model in cpu for validation (gpu for training)\n",
        "_ = model.to('cpu')\n",
        "_ = model.load_state_dict(weights) #torch.load(, map_location=torch.device('cpu'))\n",
        "_ = model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WVN9lcnLZI81",
      "metadata": {
        "id": "WVN9lcnLZI81"
      },
      "outputs": [],
      "source": [
        "test_list = [test_data+'/HCP/test/case_12',\n",
        "              test_data+'/HCP/test/case_14',\n",
        "              test_data+'/HCP/test/case_31',\n",
        "              test_data+'/ADNI/test/case_13',\n",
        "              test_data+'/ADNI/test/case_14',\n",
        "              test_data+'/ADNI/test/case_30'\n",
        "             ]\n",
        "\n",
        "test_list = [test_data+'/HCP/test/case_12',\n",
        "              test_data+'/HCP/test/case_14',\n",
        "              test_data+'/HCP/test/case_31'\n",
        "             ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7QHdvLnpOzqb",
      "metadata": {
        "id": "7QHdvLnpOzqb"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# copy model to gpu\n",
        "_ = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "Q--ILv7OelyR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q--ILv7OelyR",
        "outputId": "85d75186-ca61-4e62-8363-68f8055fad61"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/dti-transformer/dti_data/INUTR/test/case_44',\n",
              " '/content/drive/MyDrive/dti-transformer/dti_data/INUTR/test/case_15',\n",
              " '/content/drive/MyDrive/dti-transformer/dti_data/INUTR/test/case_03',\n",
              " '/content/drive/MyDrive/dti-transformer/dti_data/INUTR/test/case_34',\n",
              " '/content/drive/MyDrive/dti-transformer/dti_data/INUTR/test/case_08',\n",
              " '/content/drive/MyDrive/dti-transformer/dti_data/INUTR/test/case_28',\n",
              " '/content/drive/MyDrive/dti-transformer/dti_data/INUTR/test/case_77',\n",
              " '/content/drive/MyDrive/dti-transformer/dti_data/INUTR/test/case_04']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# get cases list\n",
        "path_list = glob.glob(os.path.join(test_data, 'INUTR', 'test', 'case_*')) #INUTR\n",
        "path_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "29xuEYvWZJAF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29xuEYvWZJAF",
        "outputId": "eaae9ac0-3c01-438c-b437-72d07e1d6ca8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/drive/MyDrive/dti-transformer/dti_data/INUTR/test/case_44\n",
            "Processing /content/drive/MyDrive/dti-transformer/dti_data/INUTR/test/case_15\n",
            "Processing /content/drive/MyDrive/dti-transformer/dti_data/INUTR/test/case_03\n",
            "Processing /content/drive/MyDrive/dti-transformer/dti_data/INUTR/test/case_34\n",
            "Processing /content/drive/MyDrive/dti-transformer/dti_data/INUTR/test/case_08\n",
            "Processing /content/drive/MyDrive/dti-transformer/dti_data/INUTR/test/case_28\n",
            "Processing /content/drive/MyDrive/dti-transformer/dti_data/INUTR/test/case_77\n",
            "Processing /content/drive/MyDrive/dti-transformer/dti_data/INUTR/test/case_04\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "test_results = [[\"Slice\",\"MSE\",\"NMSE\",\"SSIM\",\"PSNR\",\"Full path\"]]\n",
        "for data_path in path_list:\n",
        "    print(f\"Processing {data_path}\")\n",
        "    data_eval, label_eval = data_preprocessing(data_path, maps=maps, signals=signals, dti_folder='output')\n",
        "    for sidx in range(data_eval.shape[0]):\n",
        "        data = data_eval[sidx]\n",
        "        label = label_eval[sidx]\n",
        "        with torch.no_grad():\n",
        "            output = model(data)\n",
        "        # detach data\n",
        "        label_np = label.detach().numpy()\n",
        "        output_np = output.detach().numpy()\n",
        "        # calculate metrics\n",
        "        label_mean = label_np.mean()\n",
        "        mse = mean_squared_error(label_np, output_np)\n",
        "        nmse = mse/label_mean if label_mean!=0 else 0\n",
        "        ssi = ssim(label_np, output_np, data_range=label_np.max() - label_np.min()) #channel_axis = 0\n",
        "        psnr = 20*log10(1/sqrt(mse))\n",
        "        # append results\n",
        "        test_results.append([os.path.basename(data_path)+f'_{sidx}',mse,nmse,ssi,psnr,data_path])\n",
        "end = time.time()\n",
        "elapsed_time = end - start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qxQufHJhKTlD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxQufHJhKTlD",
        "outputId": "85b6e0fe-35aa-4df1-84ec-ea1611c561f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount(mount_path, True)\n",
        "os.chdir(drive_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "dweMUxPRZJH2",
      "metadata": {
        "id": "dweMUxPRZJH2"
      },
      "outputs": [],
      "source": [
        "# save results to csv file\n",
        "pd.DataFrame(test_results).to_csv(results_path+\"/test_INUTR_NORMAL_TRAIN.csv\", index=False, header=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eITYea2h_fvT"
      },
      "id": "eITYea2h_fvT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hPJhGfwp_fy0"
      },
      "id": "hPJhGfwp_fy0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Tqg4HEUYAbhe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tqg4HEUYAbhe",
        "outputId": "d0748235-3496-4313-ece2-cfa5e8cff30b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.4011349969440037"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "elapsed_time/180"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_hHktuUzLvr6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hHktuUzLvr6",
        "outputId": "e49ed95f-d290-4dcb-edca-611b3221907e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "188.0440494219462"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "elapsed_time/3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "s3G8t_XyLvuQ",
      "metadata": {
        "id": "s3G8t_XyLvuQ"
      },
      "outputs": [],
      "source": [
        "# read fsl data\n",
        "output_fsl,_ = load_nifti(os.path.join(data_path,'fsl','DTI_RGB.nii.gz'))\n",
        "output_fsl =  np.array(output_fsl.transpose(2,0,1),dtype=np.float32) #2,3,0,1\n",
        "output_fsl = torch.tensor(output_fsl)\n",
        "output_fsl = normalize_data(output_fsl)\n",
        "output_fsl = TF.resize(output_fsl, (140, 140))\n",
        "output_fsl = output_fsl.detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8m8egLmmLvx5",
      "metadata": {
        "id": "8m8egLmmLvx5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "toc-showmarkdowntxt": false
  },
  "nbformat": 4,
  "nbformat_minor": 5
}